A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. 
The analytics team is particularly interested in understanding what songs users are listening to

In this project, I built an ETL pipeline using Spark for a data lake hosted on S3. 
It is loading data from S3, process the data into analytics tables using Spark, and load them back into S3. 

Source Data resides in two directories that contain files in JSON format:
s3a://udacity-dend/song_data : Contains metadata about a songs and the artists informations.
s3a://udacity-dend/log_data : Consists of log files generated by the streaming app based on the songs in the dataset above.

Target Files are;
Fact Table;
songplays --> contains when, who listen which song of an artist 

Dimension Tables;
users --> users in the app
songs --> songs in music database
artists --> artists in music database
time --> broken down into specific time units

Target Data stored as parquet files.